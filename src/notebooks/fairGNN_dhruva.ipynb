{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b94d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,recall_score,f1_score\n",
    "\n",
    "\n",
    "import scipy.sparse as sp\n",
    "import sys\n",
    "# insert at 1, 0 is the script path (or '' in REPL)\n",
    "sys.path.insert(1, '../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d54ba9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(acc=0.688, alpha=4, attn_drop=0.0, beta=0.01, cuda=True, dataset='nba', dropout=0.5, epochs=2000, fastmode=False, hidden=128, label_number=500, lr=0.001, model='GAT', negative_slope=0.2, no_cuda=False, num_heads=1, num_hidden=64, num_layers=1, num_out_heads=1, residual=False, roc=0.745, seed=42, sens_number=200, weight_decay=1e-05)\n",
      "nba\n",
      "nba\n",
      "Loading nba dataset from ../../dataset/NBA\n",
      "213\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import dgl\n",
    "from utils import feature_norm\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,recall_score,f1_score\n",
    "import pickle as pk\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import load_data, accuracy,load_pokec\n",
    "from models.FairGNN import FairGNN, FairGNN1\n",
    "from models.VarFairGNN import VarFairGNN\n",
    "\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Disables CUDA training.')\n",
    "parser.add_argument('--fastmode', action='store_true', default=False,\n",
    "                    help='Validate during training pass.')\n",
    "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=2000,\n",
    "                    help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default=0.001,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-5,\n",
    "                    help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--hidden', type=int, default=128,\n",
    "                    help='Number of hidden units of the sensitive attribute estimator')\n",
    "parser.add_argument('--dropout', type=float, default=.5,\n",
    "                    help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--alpha', type=float, default=4,\n",
    "                    help='The hyperparameter of alpha')\n",
    "parser.add_argument('--beta', type=float, default=0.01,\n",
    "                    help='The hyperparameter of beta')\n",
    "parser.add_argument('--model', type=str, default=\"GAT\",\n",
    "                    help='the type of model GCN/GAT')\n",
    "parser.add_argument('--dataset', type=str, default='nba',\n",
    "                    choices=['pokec_z','pokec_n','nba'])\n",
    "parser.add_argument('--num-hidden', type=int, default=64,\n",
    "                    help='Number of hidden units of classifier.')\n",
    "parser.add_argument(\"--num-heads\", type=int, default=1,\n",
    "                        help=\"number of hidden attention heads\")\n",
    "parser.add_argument(\"--num-out-heads\", type=int, default=1,\n",
    "                    help=\"number of output attention heads\")\n",
    "parser.add_argument(\"--num-layers\", type=int, default=1,\n",
    "                    help=\"number of hidden layers\")\n",
    "parser.add_argument(\"--residual\", action=\"store_true\", default=False,\n",
    "                    help=\"use residual connection\")\n",
    "parser.add_argument(\"--attn-drop\", type=float, default=.0,\n",
    "                    help=\"attention dropout\")\n",
    "parser.add_argument('--negative-slope', type=float, default=0.2,\n",
    "                    help=\"the negative slope of leaky relu\")\n",
    "parser.add_argument('--acc', type=float, default=0.688,\n",
    "                    help='the selected FairGNN accuracy on val would be at least this high')\n",
    "parser.add_argument('--roc', type=float, default=0.745,\n",
    "                    help='the selected FairGNN ROC score on val would be at least this high')\n",
    "parser.add_argument('--sens_number', type=int, default=200,\n",
    "                    help=\"the number of sensitive attributes\")\n",
    "parser.add_argument('--label_number', type=int, default=500,\n",
    "                    help=\"the number of labels\")\n",
    "\n",
    "\n",
    "def fair_metric(output,idx):\n",
    "    val_y = labels[idx].cpu().numpy()\n",
    "    idx_s0 = sens.cpu().numpy()[idx.cpu().numpy()]==0\n",
    "    idx_s1 = sens.cpu().numpy()[idx.cpu().numpy()]==1\n",
    "\n",
    "    idx_s0_y1 = np.bitwise_and(idx_s0,val_y==1)\n",
    "    idx_s1_y1 = np.bitwise_and(idx_s1,val_y==1)\n",
    "\n",
    "#     pdb.set_trace()\n",
    "    pred_y = (output[idx].squeeze()>0).type_as(labels).cpu().numpy()\n",
    "    parity = abs(sum(pred_y[idx_s0])/sum(idx_s0)-sum(pred_y[idx_s1])/sum(idx_s1))\n",
    "    equality = abs(sum(pred_y[idx_s0_y1])/sum(idx_s0_y1)-sum(pred_y[idx_s1_y1])/sum(idx_s1_y1))\n",
    "    # counterfair = sum(pred_y[])\n",
    "\n",
    "    return parity,equality\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "\n",
    "\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "print(args)\n",
    "#%%\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "# Load datprint(args.dataset)\n",
    "print(args.dataset)\n",
    "\n",
    "if args.dataset != 'nba':\n",
    "    if args.dataset == 'pokec_z':\n",
    "        dataset = 'region_job'\n",
    "    else:\n",
    "        dataset = 'region_job_2'\n",
    "    sens_attr = \"region\"\n",
    "    predict_attr = \"I_am_working_in_field\"\n",
    "    label_number = args.label_number\n",
    "    sens_number = args.sens_number\n",
    "    seed = 20\n",
    "    path=\"../../dataset/pokec/\"\n",
    "    test_idx=False\n",
    "else:\n",
    "    dataset = 'nba'\n",
    "    sens_attr = \"country\"\n",
    "    predict_attr = \"SALARY\"\n",
    "    label_number = 100\n",
    "    sens_number = 50\n",
    "    seed = 20\n",
    "    path = \"../../dataset/NBA\"\n",
    "    test_idx = True\n",
    "print(dataset)\n",
    "\n",
    "adj, features, labels, idx_train, idx_val, idx_test, sens, idx_sens_train = load_pokec(dataset,\n",
    "                                                                                    sens_attr,\n",
    "                                                                                    predict_attr,\n",
    "                                                                                    path=path,\n",
    "                                                                                    label_number=label_number,\n",
    "                                                                                    sens_number=sens_number,\n",
    "                                                                                    seed=seed,test_idx=test_idx)\n",
    "print(len(idx_test))\n",
    "\n",
    "G = dgl.from_scipy(adj)\n",
    "if dataset == 'nba':\n",
    "    features = feature_norm(features)\n",
    "\n",
    "labels[labels>1]=1\n",
    "if sens_attr:\n",
    "    sens[sens>0]=1\n",
    "# Model and optimizer\n",
    "\n",
    "args.data = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918a00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).cuda()\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).cpu().numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).cpu().numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super(MLPPredictor, self).__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def forward(self, edges1,edges2): # N,h (N,h)\n",
    "        h = torch.cat([edges1, edges2], 1)\n",
    "        out=self.W2(F.relu(self.W1(h))).squeeze(1)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b98c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_similarity_graph(args,G,features,labels,idx_train,idx_val,idx_test, sens,idx_sens_train, noisy_estimate_factor=1.0,test_split=0.1):\n",
    "\n",
    "    \n",
    "    model = FairGNN1(nfeat = features.shape[1], args = args)\n",
    "    # model = VarFairGNN(nfeat = features.shape[1], args = args)\n",
    "    # model.estimator.load_state_dict(torch.load(\"./checkpoint/GCN_sens_{}_ns_{}\".format(dataset,sens_number)))\n",
    "    if args.cuda:\n",
    "        G = G.to(torch.device('cuda:0'))\n",
    "        model.cuda()\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "        idx_train = idx_train.cuda()\n",
    "        idx_val = idx_val.cuda()\n",
    "        idx_test = idx_test.cuda()\n",
    "        sens = sens.cuda()\n",
    "        idx_sens_train = idx_sens_train.cuda()\n",
    "\n",
    "        \n",
    "  \n",
    "    # Train model\n",
    "    t_total = time.time()\n",
    "    best_result = {}\n",
    "    best_fair = 100\n",
    "\n",
    "    acc_test_list = []\n",
    "    roc_test_list = []\n",
    "    parity_list = []\n",
    "    equality_list = []\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score,roc_auc_score,recall_score,f1_score\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        model.optimize(G,features,labels,idx_train,sens,idx_sens_train)\n",
    "        cov = model.cov\n",
    "        cls_loss = model.cls_loss\n",
    "        adv_loss = model.adv_loss\n",
    "        model.eval()\n",
    "        output,s,z = model(G, features)\n",
    "        acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "        roc_val = roc_auc_score(labels[idx_val].cpu().numpy(),output[idx_val].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "        acc_sens = accuracy(s[idx_test], sens[idx_test])\n",
    "\n",
    "        parity_val, equality_val = fair_metric(output,idx_val)\n",
    "\n",
    "        acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "        roc_test = roc_auc_score(labels[idx_test].cpu().numpy(),output[idx_test].detach().cpu().numpy())\n",
    "        parity,equality = fair_metric(output,idx_test)\n",
    "        if acc_val > args.acc and roc_val > args.roc:\n",
    "            acc_test_list.append(acc_test.item())\n",
    "            roc_test_list.append(roc_test)\n",
    "            parity_list.append(parity)\n",
    "            equality_list.append(equality)    \n",
    "            if best_fair > parity_val + equality_val :\n",
    "                best_fair = parity_val + equality_val\n",
    "\n",
    "                best_result['acc'] = acc_test.item()\n",
    "                best_result['roc'] = roc_test\n",
    "                best_result['parity'] = parity\n",
    "                best_result['equality'] = equality\n",
    "\n",
    "            print(\"=================================\")\n",
    "\n",
    "            print('Epoch: {:04d}'.format(epoch+1),\n",
    "                'cov: {:.4f}'.format(cov.item()),\n",
    "                'cls: {:.4f}'.format(cls_loss.item()),\n",
    "                'adv: {:.4f}'.format(adv_loss.item()),\n",
    "                'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "                \"roc_val: {:.4f}\".format(roc_val),\n",
    "                \"parity_val: {:.4f}\".format(parity_val),\n",
    "                \"equality: {:.4f}\".format(equality_val))\n",
    "            print(\"Test:\",\n",
    "                    \"accuracy: {:.4f}\".format(acc_test.item()),\n",
    "                    \"roc: {:.4f}\".format(roc_test),\n",
    "                    \"acc_sens: {:.4f}\".format(acc_sens),\n",
    "                    \"parity: {:.4f}\".format(parity),\n",
    "                    \"equality: {:.4f}\".format(equality))\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "    print('============performace on test set=============')\n",
    "    if len(best_result) > 0:\n",
    "        print(\"Test:\",\n",
    "                \"accuracy: {:.4f}\".format(best_result['acc']),\n",
    "                \"roc: {:.4f}\".format(best_result['roc']),\n",
    "                \"acc_sens: {:.4f}\".format(acc_sens),\n",
    "                \"parity: {:.4f}\".format(best_result['parity']),\n",
    "                \"equality: {:.4f}\".format(best_result['equality']))\n",
    "        print(\"Test:\",\n",
    "                \"accuracy: {:.4f}\".format(np.mean(acc_test_list)),\n",
    "                \"roc: {:.4f}\".format(np.mean(roc_test_list)),\n",
    "                \"parity: {:.4f}\".format(np.mean(parity_list)),\n",
    "                \"equality: {:.4f}\".format(np.mean(equality_list)))\n",
    "    else:\n",
    "        print(\"Please set smaller acc/roc thresholds\")\n",
    "     \n",
    "    g=G\n",
    "    u, v = g.cpu().edges()\n",
    "\n",
    "    eids = np.arange(g.number_of_edges())\n",
    "    eids = np.random.permutation(eids)\n",
    "    nedges=int(len(eids)*noisy_estimate_factor)\n",
    "    test_size = int(nedges * test_split)\n",
    "    train_size = nedges - test_size\n",
    "    test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "    train_pos_u, train_pos_v = u[eids[test_size:nedges]], v[eids[test_size:nedges]]\n",
    "\n",
    "    # Find all negative edges and split them for training and testing\n",
    "    adj1 = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "    adj1_neg = 1 - adj1.todense() - np.eye(g.number_of_nodes())\n",
    "    neg_u, neg_v = np.where(adj1_neg != 0)\n",
    "\n",
    "    neg_eids = np.random.choice(len(neg_u), nedges// 2)\n",
    "    test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "    train_neg_u, train_neg_v = neg_u[neg_eids[test_size:nedges ]], neg_v[neg_eids[test_size:nedges ]]\n",
    "    \n",
    "    train_pos_edges1=z[train_pos_u].cuda().detach()\n",
    "    train_pos_edges2=z[train_pos_v].cuda().detach()\n",
    "    test_pos_edges1=z[test_pos_u].cuda().detach()\n",
    "    test_pos_edges2=z[test_pos_v].cuda().detach()\n",
    "    train_neg_edges1=z[train_neg_u].cuda().detach()\n",
    "    train_neg_edges2=z[train_neg_v].cuda().detach()\n",
    "    test_neg_edges1=z[test_neg_u].cuda().detach()\n",
    "    test_neg_edges2=z[test_neg_v].cuda().detach()\n",
    "    \n",
    "    pred1 = MLPPredictor(args.num_hidden)\n",
    "    pred1.cuda()\n",
    "\n",
    "        # ----------- 3. set up loss and optimizer -------------- #\n",
    "    # in this case, loss will in training loop\n",
    "    optimizer = torch.optim.Adam(pred1.parameters(), lr=0.002)\n",
    "\n",
    "    # ----------- 4. training -------------------------------- #\n",
    "    all_logits = []\n",
    "    for e in range(100):\n",
    "        # forward\n",
    "        pred1.train()\n",
    "        pos_score = pred1(train_pos_edges1, train_pos_edges2)\n",
    "        neg_score = pred1(train_neg_edges1, train_neg_edges1)\n",
    "        loss = compute_loss(pos_score, neg_score)\n",
    "    #     print('In epoch {}, loss: {}'.format(e, loss.data))\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            print('In epoch {}, loss: {}'.format(e, loss.data))\n",
    "\n",
    "    #     ----------- 5. check results ------------------------ #\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "        with torch.no_grad():\n",
    "            pos_score = pred1(test_pos_edges1, test_pos_edges2)\n",
    "            neg_score = pred1(test_neg_edges1, test_neg_edges1)\n",
    "            print('AUC', compute_auc(pos_score, neg_score))\n",
    "\n",
    "\n",
    "    pred1.eval()\n",
    "    # ----------- 5. check results ------------------------ #\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    with torch.no_grad():\n",
    "        pos_score = pred1(test_pos_edges1, test_pos_edges2)\n",
    "        neg_score = pred1(test_neg_edges1, test_neg_edges1)\n",
    "        print('AUC', compute_auc(pos_score, neg_score))\n",
    "        \n",
    "    #for evaluation just use\n",
    "    #torch.special.expit(pos_score)\n",
    "    return z,pred1,pos_score,neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6897d06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Epoch: 0822 cov: 0.0005 cls: 0.4683 adv: 0.6830 acc_val: 0.6948 roc_val: 0.7564 parity_val: 0.0554 equality: 0.1515\n",
      "Test: accuracy: 0.6948 roc: 0.7564 acc_sens: 0.7230 parity: 0.0554 equality: 0.1515\n",
      "=================================\n",
      "Epoch: 0878 cov: 0.0002 cls: 0.4558 adv: 0.6832 acc_val: 0.6901 roc_val: 0.7464 parity_val: 0.0006 equality: 0.0676\n",
      "Test: accuracy: 0.6901 roc: 0.7464 acc_sens: 0.7230 parity: 0.0006 equality: 0.0676\n",
      "=================================\n",
      "Epoch: 0892 cov: 0.0001 cls: 0.4168 adv: 0.6850 acc_val: 0.6901 roc_val: 0.7499 parity_val: 0.0251 equality: 0.1046\n",
      "Test: accuracy: 0.6901 roc: 0.7499 acc_sens: 0.7230 parity: 0.0251 equality: 0.1046\n",
      "=================================\n",
      "Epoch: 0895 cov: 0.0024 cls: 0.4495 adv: 0.6804 acc_val: 0.6901 roc_val: 0.7566 parity_val: 0.0215 equality: 0.0917\n",
      "Test: accuracy: 0.6901 roc: 0.7566 acc_sens: 0.7230 parity: 0.0215 equality: 0.0917\n",
      "=================================\n",
      "Epoch: 0896 cov: 0.0035 cls: 0.4783 adv: 0.6820 acc_val: 0.6995 roc_val: 0.7554 parity_val: 0.0006 equality: 0.0796\n",
      "Test: accuracy: 0.6995 roc: 0.7554 acc_sens: 0.7230 parity: 0.0006 equality: 0.0796\n",
      "=================================\n",
      "Epoch: 0904 cov: 0.0003 cls: 0.4427 adv: 0.6829 acc_val: 0.6948 roc_val: 0.7552 parity_val: 0.0070 equality: 0.0676\n",
      "Test: accuracy: 0.6948 roc: 0.7552 acc_sens: 0.7230 parity: 0.0070 equality: 0.0676\n",
      "=================================\n",
      "Epoch: 0930 cov: 0.0008 cls: 0.4465 adv: 0.6827 acc_val: 0.6948 roc_val: 0.7619 parity_val: 0.0161 equality: 0.0805\n",
      "Test: accuracy: 0.6948 roc: 0.7619 acc_sens: 0.7230 parity: 0.0161 equality: 0.0805\n",
      "=================================\n",
      "Epoch: 0931 cov: 0.0004 cls: 0.4617 adv: 0.6841 acc_val: 0.6995 roc_val: 0.7618 parity_val: 0.0294 equality: 0.0443\n",
      "Test: accuracy: 0.6995 roc: 0.7618 acc_sens: 0.7230 parity: 0.0294 equality: 0.0443\n",
      "=================================\n",
      "Epoch: 0932 cov: 0.0007 cls: 0.4061 adv: 0.6842 acc_val: 0.6901 roc_val: 0.7601 parity_val: 0.0189 equality: 0.0680\n",
      "Test: accuracy: 0.6901 roc: 0.7601 acc_sens: 0.7230 parity: 0.0189 equality: 0.0680\n",
      "=================================\n",
      "Epoch: 0933 cov: 0.0015 cls: 0.4097 adv: 0.6831 acc_val: 0.7042 roc_val: 0.7572 parity_val: 0.0229 equality: 0.0564\n",
      "Test: accuracy: 0.7042 roc: 0.7572 acc_sens: 0.7230 parity: 0.0229 equality: 0.0564\n",
      "=================================\n",
      "Epoch: 0934 cov: 0.0020 cls: 0.3820 adv: 0.6813 acc_val: 0.6995 roc_val: 0.7559 parity_val: 0.0294 equality: 0.0443\n",
      "Test: accuracy: 0.6995 roc: 0.7559 acc_sens: 0.7230 parity: 0.0294 equality: 0.0443\n",
      "=================================\n",
      "Epoch: 0935 cov: 0.0008 cls: 0.4422 adv: 0.6813 acc_val: 0.6995 roc_val: 0.7548 parity_val: 0.0294 equality: 0.0443\n",
      "Test: accuracy: 0.6995 roc: 0.7548 acc_sens: 0.7230 parity: 0.0294 equality: 0.0443\n",
      "=================================\n",
      "Epoch: 0936 cov: 0.0008 cls: 0.5024 adv: 0.6831 acc_val: 0.6948 roc_val: 0.7544 parity_val: 0.0099 equality: 0.0564\n",
      "Test: accuracy: 0.6948 roc: 0.7544 acc_sens: 0.7230 parity: 0.0099 equality: 0.0564\n",
      "=================================\n",
      "Epoch: 0937 cov: 0.0001 cls: 0.4039 adv: 0.6813 acc_val: 0.6948 roc_val: 0.7568 parity_val: 0.0006 equality: 0.0921\n",
      "Test: accuracy: 0.6948 roc: 0.7568 acc_sens: 0.7230 parity: 0.0006 equality: 0.0921\n",
      "=================================\n",
      "Epoch: 0959 cov: 0.0002 cls: 0.4274 adv: 0.6820 acc_val: 0.6995 roc_val: 0.7496 parity_val: 0.0240 equality: 0.0796\n",
      "Test: accuracy: 0.6995 roc: 0.7496 acc_sens: 0.7230 parity: 0.0240 equality: 0.0796\n",
      "=================================\n",
      "Epoch: 0986 cov: 0.0023 cls: 0.4424 adv: 0.6828 acc_val: 0.6901 roc_val: 0.7567 parity_val: 0.0215 equality: 0.0039\n",
      "Test: accuracy: 0.6901 roc: 0.7567 acc_sens: 0.7230 parity: 0.0215 equality: 0.0039\n",
      "=================================\n",
      "Epoch: 0992 cov: 0.0007 cls: 0.4839 adv: 0.6826 acc_val: 0.6948 roc_val: 0.7525 parity_val: 0.0099 equality: 0.0564\n",
      "Test: accuracy: 0.6948 roc: 0.7525 acc_sens: 0.7230 parity: 0.0099 equality: 0.0564\n",
      "=================================\n",
      "Epoch: 0993 cov: 0.0018 cls: 0.4320 adv: 0.6845 acc_val: 0.6901 roc_val: 0.7545 parity_val: 0.0189 equality: 0.0680\n",
      "Test: accuracy: 0.6901 roc: 0.7545 acc_sens: 0.7230 parity: 0.0189 equality: 0.0680\n",
      "=================================\n",
      "Epoch: 0999 cov: 0.0013 cls: 0.4782 adv: 0.6819 acc_val: 0.6948 roc_val: 0.7582 parity_val: 0.0229 equality: 0.0443\n",
      "Test: accuracy: 0.6948 roc: 0.7582 acc_sens: 0.7230 parity: 0.0229 equality: 0.0443\n",
      "=================================\n",
      "Epoch: 1065 cov: 0.0015 cls: 0.4109 adv: 0.6827 acc_val: 0.6948 roc_val: 0.7455 parity_val: 0.0229 equality: 0.0443\n",
      "Test: accuracy: 0.6948 roc: 0.7455 acc_sens: 0.7230 parity: 0.0229 equality: 0.0443\n",
      "=================================\n",
      "Epoch: 1093 cov: 0.0007 cls: 0.4005 adv: 0.6830 acc_val: 0.6901 roc_val: 0.7481 parity_val: 0.0006 equality: 0.0676\n",
      "Test: accuracy: 0.6901 roc: 0.7481 acc_sens: 0.7230 parity: 0.0006 equality: 0.0676\n",
      "=================================\n",
      "Epoch: 1115 cov: 0.0015 cls: 0.5148 adv: 0.6825 acc_val: 0.6901 roc_val: 0.7464 parity_val: 0.0294 equality: 0.0323\n",
      "Test: accuracy: 0.6901 roc: 0.7464 acc_sens: 0.7230 parity: 0.0294 equality: 0.0323\n",
      "=================================\n",
      "Epoch: 1116 cov: 0.0023 cls: 0.4038 adv: 0.6829 acc_val: 0.7042 roc_val: 0.7469 parity_val: 0.0254 equality: 0.0323\n",
      "Test: accuracy: 0.7042 roc: 0.7469 acc_sens: 0.7230 parity: 0.0254 equality: 0.0323\n",
      "=================================\n",
      "Epoch: 1117 cov: 0.0011 cls: 0.4122 adv: 0.6811 acc_val: 0.7042 roc_val: 0.7471 parity_val: 0.0150 equality: 0.0202\n",
      "Test: accuracy: 0.7042 roc: 0.7471 acc_sens: 0.7230 parity: 0.0150 equality: 0.0202\n",
      "=================================\n",
      "Epoch: 1118 cov: 0.0002 cls: 0.5376 adv: 0.6819 acc_val: 0.6948 roc_val: 0.7470 parity_val: 0.0124 equality: 0.0323\n",
      "Test: accuracy: 0.6948 roc: 0.7470 acc_sens: 0.7230 parity: 0.0124 equality: 0.0323\n",
      "=================================\n",
      "Epoch: 1119 cov: 0.0018 cls: 0.3952 adv: 0.6833 acc_val: 0.6901 roc_val: 0.7462 parity_val: 0.0294 equality: 0.0323\n",
      "Test: accuracy: 0.6901 roc: 0.7462 acc_sens: 0.7230 parity: 0.0294 equality: 0.0323\n",
      "=================================\n",
      "Epoch: 1155 cov: 0.0004 cls: 0.4052 adv: 0.6831 acc_val: 0.6901 roc_val: 0.7547 parity_val: 0.0085 equality: 0.0559\n",
      "Test: accuracy: 0.6901 roc: 0.7547 acc_sens: 0.7230 parity: 0.0085 equality: 0.0559\n",
      "=================================\n",
      "Epoch: 1157 cov: 0.0006 cls: 0.4452 adv: 0.6817 acc_val: 0.6948 roc_val: 0.7486 parity_val: 0.0229 equality: 0.0443\n",
      "Test: accuracy: 0.6948 roc: 0.7486 acc_sens: 0.7230 parity: 0.0229 equality: 0.0443\n",
      "=================================\n",
      "Epoch: 1158 cov: 0.0002 cls: 0.4339 adv: 0.6848 acc_val: 0.6948 roc_val: 0.7460 parity_val: 0.0333 equality: 0.0086\n",
      "Test: accuracy: 0.6948 roc: 0.7460 acc_sens: 0.7230 parity: 0.0333 equality: 0.0086\n",
      "=================================\n",
      "Epoch: 1195 cov: 0.0021 cls: 0.3731 adv: 0.6833 acc_val: 0.6901 roc_val: 0.7463 parity_val: 0.0215 equality: 0.0439\n",
      "Test: accuracy: 0.6901 roc: 0.7463 acc_sens: 0.7230 parity: 0.0215 equality: 0.0439\n",
      "=================================\n",
      "Epoch: 1196 cov: 0.0007 cls: 0.4753 adv: 0.6818 acc_val: 0.6901 roc_val: 0.7522 parity_val: 0.0132 equality: 0.0426\n",
      "Test: accuracy: 0.6901 roc: 0.7522 acc_sens: 0.7230 parity: 0.0132 equality: 0.0426\n",
      "=================================\n",
      "Epoch: 1200 cov: 0.0009 cls: 0.4468 adv: 0.6806 acc_val: 0.6948 roc_val: 0.7528 parity_val: 0.0175 equality: 0.0318\n",
      "Test: accuracy: 0.6948 roc: 0.7528 acc_sens: 0.7230 parity: 0.0175 equality: 0.0318\n",
      "=================================\n",
      "Epoch: 1258 cov: 0.0021 cls: 0.3796 adv: 0.6813 acc_val: 0.6901 roc_val: 0.7460 parity_val: 0.0135 equality: 0.0555\n",
      "Test: accuracy: 0.6901 roc: 0.7460 acc_sens: 0.7230 parity: 0.0135 equality: 0.0555\n",
      "=================================\n",
      "Epoch: 1259 cov: 0.0017 cls: 0.3445 adv: 0.6840 acc_val: 0.6948 roc_val: 0.7465 parity_val: 0.0096 equality: 0.0435\n",
      "Test: accuracy: 0.6948 roc: 0.7465 acc_sens: 0.7230 parity: 0.0096 equality: 0.0435\n",
      "=================================\n",
      "Epoch: 1260 cov: 0.0002 cls: 0.4245 adv: 0.6819 acc_val: 0.6901 roc_val: 0.7470 parity_val: 0.0161 equality: 0.0314\n",
      "Test: accuracy: 0.6901 roc: 0.7470 acc_sens: 0.7230 parity: 0.0161 equality: 0.0314\n",
      "=================================\n",
      "Epoch: 1261 cov: 0.0005 cls: 0.4273 adv: 0.6835 acc_val: 0.6948 roc_val: 0.7474 parity_val: 0.0096 equality: 0.0435\n",
      "Test: accuracy: 0.6948 roc: 0.7474 acc_sens: 0.7230 parity: 0.0096 equality: 0.0435\n",
      "=================================\n",
      "Epoch: 1262 cov: 0.0022 cls: 0.4155 adv: 0.6827 acc_val: 0.6948 roc_val: 0.7479 parity_val: 0.0096 equality: 0.0435\n",
      "Test: accuracy: 0.6948 roc: 0.7479 acc_sens: 0.7230 parity: 0.0096 equality: 0.0435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Epoch: 1383 cov: 0.0010 cls: 0.5091 adv: 0.6822 acc_val: 0.6901 roc_val: 0.7470 parity_val: 0.0045 equality: 0.0202\n",
      "Test: accuracy: 0.6901 roc: 0.7470 acc_sens: 0.7230 parity: 0.0045 equality: 0.0202\n",
      "Optimization Finished!\n",
      "Total time elapsed: 56.8426s\n",
      "============performace on test set=============\n",
      "Test: accuracy: 0.6901 roc: 0.7470 acc_sens: 0.7230 parity: 0.0045 equality: 0.0202\n",
      "Test: accuracy: 0.6943 roc: 0.7517 parity: 0.0179 equality: 0.0533\n",
      "In epoch 0, loss: 0.7478482127189636\n",
      "AUC 0.5676658204666514\n",
      "AUC 0.6232696604835981\n",
      "AUC 0.6076970319221269\n",
      "AUC 0.6148915115774511\n",
      "AUC 0.6322087870411813\n",
      "In epoch 5, loss: 0.5891706347465515\n",
      "AUC 0.6520317769175314\n",
      "AUC 0.666793155346606\n",
      "AUC 0.6769902641442389\n",
      "AUC 0.6857401915395943\n",
      "AUC 0.693596868262716\n",
      "In epoch 10, loss: 0.5613959431648254\n",
      "AUC 0.7023912126171498\n",
      "AUC 0.7122648036599574\n",
      "AUC 0.7232381415260984\n",
      "AUC 0.7339753007540633\n",
      "AUC 0.7455303299496723\n",
      "In epoch 15, loss: 0.5288335084915161\n",
      "AUC 0.7571526252131159\n",
      "AUC 0.7694317789675449\n",
      "AUC 0.7814993115371343\n",
      "AUC 0.7926125201157573\n",
      "AUC 0.8052948431910509\n",
      "In epoch 20, loss: 0.49924203753471375\n",
      "AUC 0.8182551993467291\n",
      "AUC 0.830653296592536\n",
      "AUC 0.8406332320854446\n",
      "AUC 0.8485815187866654\n",
      "AUC 0.855164411082373\n",
      "In epoch 25, loss: 0.46952688694000244\n",
      "AUC 0.8602021057055291\n",
      "AUC 0.8642015539102299\n",
      "AUC 0.8682242783098322\n",
      "AUC 0.8727125266074668\n",
      "AUC 0.8779569309247952\n",
      "In epoch 30, loss: 0.44333168864250183\n",
      "AUC 0.8831355639757963\n",
      "AUC 0.8871672571844432\n",
      "AUC 0.8904389505980914\n",
      "AUC 0.8933749543017824\n",
      "AUC 0.8958945490141144\n",
      "In epoch 35, loss: 0.4200417995452881\n",
      "AUC 0.8983560600107284\n",
      "AUC 0.9009194310529212\n",
      "AUC 0.9035665109795307\n",
      "AUC 0.9063790867873213\n",
      "AUC 0.9089917862792597\n",
      "In epoch 40, loss: 0.39901795983314514\n",
      "AUC 0.9113917968709961\n",
      "AUC 0.9136122177387668\n",
      "AUC 0.9152532962508669\n",
      "AUC 0.9166539252633413\n",
      "AUC 0.9181702946211062\n",
      "In epoch 45, loss: 0.3805485665798187\n",
      "AUC 0.9201248543636245\n",
      "AUC 0.9224093381531427\n",
      "AUC 0.9243814084276054\n",
      "AUC 0.9266223294303354\n",
      "AUC 0.928687290941332\n",
      "In epoch 50, loss: 0.3634020686149597\n",
      "AUC 0.9304370628773306\n",
      "AUC 0.9322248454802328\n",
      "AUC 0.9340211698060346\n",
      "AUC 0.9355285703547548\n",
      "AUC 0.9367041249688228\n",
      "In epoch 55, loss: 0.3482908308506012\n",
      "AUC 0.937778246623457\n",
      "AUC 0.938555329864255\n",
      "AUC 0.9394356611806028\n",
      "AUC 0.9405771556746082\n",
      "AUC 0.9419747950840676\n",
      "In epoch 60, loss: 0.334891140460968\n",
      "AUC 0.9433105070025045\n",
      "AUC 0.944508056553039\n",
      "AUC 0.9458341590332138\n",
      "AUC 0.9470594691831722\n",
      "AUC 0.9481886849505092\n",
      "In epoch 65, loss: 0.32319191098213196\n",
      "AUC 0.9493653072799396\n",
      "AUC 0.950197698176513\n",
      "AUC 0.950960901117599\n",
      "AUC 0.9518705946064145\n",
      "AUC 0.9526675373529543\n",
      "In epoch 70, loss: 0.31221598386764526\n",
      "AUC 0.9533132916041698\n",
      "AUC 0.9540376297060622\n",
      "AUC 0.9547591917480123\n",
      "AUC 0.9554553421643359\n",
      "AUC 0.9561006693294064\n",
      "In epoch 75, loss: 0.3026445508003235\n",
      "AUC 0.9567895592812654\n",
      "AUC 0.9574895534728938\n",
      "AUC 0.9583161787065099\n",
      "AUC 0.9590396626361125\n",
      "AUC 0.959745849576843\n",
      "In epoch 80, loss: 0.2936774492263794\n",
      "AUC 0.9603042647114093\n",
      "AUC 0.9607691479802243\n",
      "AUC 0.9614661525688377\n",
      "AUC 0.9619978748193425\n",
      "AUC 0.9625827692948978\n",
      "In epoch 85, loss: 0.28542360663414\n",
      "AUC 0.9630423139869004\n",
      "AUC 0.9635721143497528\n",
      "AUC 0.9639372730037139\n",
      "AUC 0.9644179584598932\n",
      "AUC 0.9648687478859236\n",
      "In epoch 90, loss: 0.2778834402561188\n",
      "AUC 0.9652465055811617\n",
      "AUC 0.9656044037706583\n",
      "AUC 0.9659225829486711\n",
      "AUC 0.9663268199848982\n",
      "AUC 0.9665764518366413\n",
      "In epoch 95, loss: 0.2707730829715729\n",
      "AUC 0.9670046056969877\n",
      "AUC 0.9673844988229506\n",
      "AUC 0.9678401997396482\n",
      "AUC 0.9682015146183045\n",
      "AUC 0.9686681062316993\n",
      "AUC 0.9686681062316993\n"
     ]
    }
   ],
   "source": [
    "z,pred,pos_score,neg_score=generate_similarity_graph(args,G,features,labels,idx_train,idx_val,idx_test, sens,idx_sens_train, noisy_estimate_factor=1.0,test_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eef02b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9998, 1.0000, 0.9995,  ..., 1.0000, 0.7308, 0.4055], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.special.expit(pos_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8b5ba76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9999, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([24650]),\n",
       " tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_auxiliary_pred(feats,pred):\n",
    "\n",
    "    def compute_similarity(pred, a, b, eps=1e-8):\n",
    "        \"\"\"\n",
    "        eps for numerical stability\n",
    "        \"\"\"\n",
    "        n=a.shape[0]\n",
    "        sim_mat= torch.zeros([n,n], dtype=torch.float32).cuda()\n",
    "        for i in range(n):\n",
    "            x=a[i].repeat(n, 1)\n",
    "#             print(x)\n",
    "            sim_mat[i]= torch.special.expit(pred(x,b))\n",
    "#             print(sim_mat[i])\n",
    "        sim_mat=(sim_mat+torch.transpose(sim_mat, 0, 1))/2\n",
    "        return sim_mat\n",
    "\n",
    "    sim_mat = compute_similarity(pred,feats,feats)\n",
    "#     print(sim_mat)\n",
    "    thresh = torch.mean(sim_mat)  + 0.6824*torch.std(sim_mat)\n",
    "    sim_mat = torch.where(sim_mat>thresh, sim_mat, torch.zeros_like(sim_mat))\n",
    "    print(thresh)\n",
    "#     print(sim_mat)\n",
    "    adj = sp.coo_matrix(sim_mat.cpu().detach().numpy(), dtype=np.float32)\n",
    "    G_aux = dgl.from_scipy(adj, eweight_name='sim')\n",
    "\n",
    "    return G_aux,adj\n",
    "sim_graph=None\n",
    "sim_graph,adj=generate_auxiliary_pred(z,pred)\n",
    "sim_graph.edges()[0].shape,sim_graph.edata['sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83498f50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "45963c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163216"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "404*404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0af75dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_auxiliary1(feats):\n",
    "\n",
    "    def compute_similarity(a, b, eps=1e-8):\n",
    "        \"\"\"\n",
    "        eps for numerical stability\n",
    "        \"\"\"\n",
    "        a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
    "        a_norm = a / torch.max(a_n, eps * torch.ones_like(a_n))\n",
    "        b_norm = b / torch.max(b_n, eps * torch.ones_like(b_n))\n",
    "        sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "        return sim_mt\n",
    "\n",
    "    sim_mat = compute_similarity(feats,feats)\n",
    "    thresh = torch.mean(sim_mat)  + 0.75*torch.std(sim_mat)\n",
    "    sim_mat = torch.where(sim_mat>thresh, sim_mat, torch.zeros_like(sim_mat))\n",
    "    adj = sp.coo_matrix(sim_mat.cpu().detach().numpy(), dtype=np.float32)\n",
    "    G_aux = dgl.from_scipy(adj, eweight_name='sim')\n",
    "\n",
    "    return G_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d538f456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([47093]),\n",
       " tensor([1.0000, 0.9773, 0.9534,  ..., 0.9907, 0.9735, 1.0000]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_graph=generate_auxiliary1(z)\n",
    "sim_graph.edges()[0].shape,sim_graph.edata['sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c477ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args.model=\"GCN\"\n",
    "args.num_hidden=128\n",
    "args.acc=0.69\n",
    "args.roc=0.76\n",
    "args.alpha=100\n",
    "args.beta=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "55c7ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Epoch: 0456 cls: 0.6716 lip: 64.3662 acc_val: 0.6948 roc_val: 0.7774 parity_val: 0.0611 equality: 0.0783\n",
      "Test: accuracy: 0.6948 roc: 0.7774 parity: 0.0611 equality: 0.0783\n",
      "=================================\n",
      "Epoch: 0585 cls: 0.6706 lip: 71.4568 acc_val: 0.6948 roc_val: 0.7806 parity_val: 0.0351 equality: 0.0542\n",
      "Test: accuracy: 0.6948 roc: 0.7806 parity: 0.0351 equality: 0.0542\n",
      "=================================\n",
      "Epoch: 0699 cls: 0.6672 lip: 74.3355 acc_val: 0.6948 roc_val: 0.7815 parity_val: 0.0715 equality: 0.1140\n",
      "Test: accuracy: 0.6948 roc: 0.7815 parity: 0.0715 equality: 0.1140\n",
      "=================================\n",
      "Epoch: 0734 cls: 0.6731 lip: 44.9744 acc_val: 0.6948 roc_val: 0.7694 parity_val: 0.0975 equality: 0.1381\n",
      "Test: accuracy: 0.6948 roc: 0.7694 parity: 0.0975 equality: 0.1381\n",
      "=================================\n",
      "Epoch: 0868 cls: 0.6698 lip: 59.3132 acc_val: 0.7089 roc_val: 0.7831 parity_val: 0.0597 equality: 0.0908\n",
      "Test: accuracy: 0.7089 roc: 0.7831 parity: 0.0597 equality: 0.0908\n",
      "=================================\n",
      "Epoch: 0945 cls: 0.6679 lip: 68.2695 acc_val: 0.7042 roc_val: 0.7778 parity_val: 0.0506 equality: 0.1024\n",
      "Test: accuracy: 0.7042 roc: 0.7778 parity: 0.0506 equality: 0.1024\n",
      "=================================\n",
      "Epoch: 1018 cls: 0.6651 lip: 78.1506 acc_val: 0.6948 roc_val: 0.7796 parity_val: 0.0247 equality: 0.0663\n",
      "Test: accuracy: 0.6948 roc: 0.7796 parity: 0.0247 equality: 0.0663\n",
      "=================================\n",
      "Epoch: 1029 cls: 0.6664 lip: 91.3808 acc_val: 0.7042 roc_val: 0.7825 parity_val: 0.0351 equality: 0.0663\n",
      "Test: accuracy: 0.7042 roc: 0.7825 parity: 0.0351 equality: 0.0663\n",
      "=================================\n",
      "Epoch: 1152 cls: 0.6648 lip: 91.8315 acc_val: 0.7230 roc_val: 0.7847 parity_val: 0.0402 equality: 0.0430\n",
      "Test: accuracy: 0.7230 roc: 0.7847 parity: 0.0402 equality: 0.0430\n",
      "=================================\n",
      "Epoch: 1166 cls: 0.6629 lip: 101.9886 acc_val: 0.7089 roc_val: 0.7774 parity_val: 0.0416 equality: 0.0783\n",
      "Test: accuracy: 0.7089 roc: 0.7774 parity: 0.0416 equality: 0.0783\n",
      "=================================\n",
      "Epoch: 1175 cls: 0.6669 lip: 86.2981 acc_val: 0.7136 roc_val: 0.7821 parity_val: 0.0272 equality: 0.0667\n",
      "Test: accuracy: 0.7136 roc: 0.7821 parity: 0.0272 equality: 0.0667\n",
      "=================================\n",
      "Epoch: 1238 cls: 0.6641 lip: 96.2243 acc_val: 0.7089 roc_val: 0.7832 parity_val: 0.0156 equality: 0.0542\n",
      "Test: accuracy: 0.7089 roc: 0.7832 parity: 0.0156 equality: 0.0542\n",
      "=================================\n",
      "Epoch: 1259 cls: 0.6627 lip: 96.7223 acc_val: 0.7136 roc_val: 0.7838 parity_val: 0.0247 equality: 0.0426\n",
      "Test: accuracy: 0.7136 roc: 0.7838 parity: 0.0247 equality: 0.0426\n",
      "=================================\n",
      "Epoch: 1275 cls: 0.6668 lip: 82.8729 acc_val: 0.7042 roc_val: 0.7824 parity_val: 0.0351 equality: 0.0663\n",
      "Test: accuracy: 0.7042 roc: 0.7824 parity: 0.0351 equality: 0.0663\n",
      "=================================\n",
      "Epoch: 1310 cls: 0.6667 lip: 65.9825 acc_val: 0.7277 roc_val: 0.7822 parity_val: 0.0387 equality: 0.0435\n",
      "Test: accuracy: 0.7277 roc: 0.7822 parity: 0.0387 equality: 0.0435\n",
      "=================================\n",
      "Epoch: 1325 cls: 0.6617 lip: 89.6981 acc_val: 0.7230 roc_val: 0.7797 parity_val: 0.0193 equality: 0.0194\n",
      "Test: accuracy: 0.7230 roc: 0.7797 parity: 0.0193 equality: 0.0194\n",
      "=================================\n",
      "Epoch: 1422 cls: 0.6676 lip: 68.2243 acc_val: 0.7230 roc_val: 0.7849 parity_val: 0.0142 equality: 0.0189\n",
      "Test: accuracy: 0.7230 roc: 0.7849 parity: 0.0142 equality: 0.0189\n",
      "=================================\n",
      "Epoch: 1448 cls: 0.6582 lip: 117.6197 acc_val: 0.7465 roc_val: 0.7792 parity_val: 0.0672 equality: 0.0680\n",
      "Test: accuracy: 0.7465 roc: 0.7792 parity: 0.0672 equality: 0.0680\n",
      "=================================\n",
      "Epoch: 1452 cls: 0.6639 lip: 76.6150 acc_val: 0.7136 roc_val: 0.7777 parity_val: 0.0557 equality: 0.0671\n",
      "Test: accuracy: 0.7136 roc: 0.7777 parity: 0.0557 equality: 0.0671\n",
      "=================================\n",
      "Epoch: 1520 cls: 0.6607 lip: 79.5959 acc_val: 0.6901 roc_val: 0.7802 parity_val: 0.0338 equality: 0.0417\n",
      "Test: accuracy: 0.6901 roc: 0.7802 parity: 0.0338 equality: 0.0417\n",
      "=================================\n",
      "Epoch: 1539 cls: 0.6648 lip: 65.8435 acc_val: 0.6995 roc_val: 0.7793 parity_val: 0.0313 equality: 0.0056\n",
      "Test: accuracy: 0.6995 roc: 0.7793 parity: 0.0313 equality: 0.0056\n",
      "=================================\n",
      "Epoch: 1549 cls: 0.6601 lip: 112.2715 acc_val: 0.6948 roc_val: 0.7797 parity_val: 0.0273 equality: 0.0297\n",
      "Test: accuracy: 0.6948 roc: 0.7797 parity: 0.0273 equality: 0.0297\n",
      "=================================\n",
      "Epoch: 1559 cls: 0.6642 lip: 77.9483 acc_val: 0.6995 roc_val: 0.7719 parity_val: 0.0156 equality: 0.0422\n",
      "Test: accuracy: 0.6995 roc: 0.7719 parity: 0.0156 equality: 0.0422\n",
      "=================================\n",
      "Epoch: 1576 cls: 0.6597 lip: 125.6709 acc_val: 0.6901 roc_val: 0.7823 parity_val: 0.0053 equality: 0.0065\n",
      "Test: accuracy: 0.6901 roc: 0.7823 parity: 0.0053 equality: 0.0065\n",
      "=================================\n",
      "Epoch: 1663 cls: 0.6616 lip: 103.6363 acc_val: 0.6995 roc_val: 0.7837 parity_val: 0.0053 equality: 0.0185\n",
      "Test: accuracy: 0.6995 roc: 0.7837 parity: 0.0053 equality: 0.0185\n",
      "=================================\n",
      "Epoch: 1667 cls: 0.6581 lip: 103.5198 acc_val: 0.7183 roc_val: 0.7857 parity_val: 0.0182 equality: 0.0426\n",
      "Test: accuracy: 0.7183 roc: 0.7857 parity: 0.0182 equality: 0.0426\n",
      "=================================\n",
      "Epoch: 1688 cls: 0.6605 lip: 104.5175 acc_val: 0.7183 roc_val: 0.7793 parity_val: 0.0077 equality: 0.0546\n",
      "Test: accuracy: 0.7183 roc: 0.7793 parity: 0.0077 equality: 0.0546\n",
      "=================================\n",
      "Epoch: 1793 cls: 0.6562 lip: 137.8173 acc_val: 0.7089 roc_val: 0.7867 parity_val: 0.0362 equality: 0.0430\n",
      "Test: accuracy: 0.7089 roc: 0.7867 parity: 0.0362 equality: 0.0430\n",
      "=================================\n",
      "Epoch: 1798 cls: 0.6648 lip: 66.7388 acc_val: 0.7042 roc_val: 0.7716 parity_val: 0.0402 equality: 0.0667\n",
      "Test: accuracy: 0.7042 roc: 0.7716 parity: 0.0402 equality: 0.0667\n",
      "=================================\n",
      "Epoch: 1925 cls: 0.6608 lip: 85.4557 acc_val: 0.7042 roc_val: 0.7741 parity_val: 0.0482 equality: 0.0413\n",
      "Test: accuracy: 0.7042 roc: 0.7741 parity: 0.0482 equality: 0.0413\n",
      "=================================\n",
      "Epoch: 1960 cls: 0.6572 lip: 122.4262 acc_val: 0.6995 roc_val: 0.7747 parity_val: 0.0103 equality: 0.0297\n",
      "Test: accuracy: 0.6995 roc: 0.7747 parity: 0.0103 equality: 0.0297\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.3300s\n",
      "============performace on test set=============\n",
      "Test: accuracy: 0.6901 roc: 0.7823 parity: 0.0053 equality: 0.0065\n",
      "Test: accuracy: 0.7073 roc: 0.7799 parity: 0.0353 equality: 0.0549\n"
     ]
    }
   ],
   "source": [
    "# model = FairGNN(nfeat = features.shape[1], args = args)\n",
    "model = VarFairGNN(nfeat = features.shape[1], args = args,aux_graph=sim_graph)\n",
    "# model.estimator.load_state_dict(torch.load(\"./checkpoint/GCN_sens_{}_ns_{}\".format(dataset,sens_number)))\n",
    "if args.cuda:\n",
    "    G = G.to(torch.device('cuda:0'))\n",
    "    model.cuda()\n",
    "    features = features.cuda()\n",
    "    labels = labels.cuda()\n",
    "    idx_train = idx_train.cuda()\n",
    "    idx_val = idx_val.cuda()\n",
    "    idx_test = idx_test.cuda()\n",
    "    sens = sens.cuda()\n",
    "    idx_sens_train = idx_sens_train.cuda()\n",
    "\n",
    "\n",
    "# Train model\n",
    "t_total = time.time()\n",
    "best_result = {}\n",
    "best_fair = 100\n",
    "\n",
    "acc_test_list = []\n",
    "roc_test_list = []\n",
    "parity_list = []\n",
    "equality_list = []\n",
    "loss_list = {'cls': [], 'lip':[]}\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    model.optimize(G,features,labels,idx_train,sens,idx_sens_train)\n",
    "    cls_loss = model.cls_loss\n",
    "    lip_loss = model.lip_loss\n",
    "    loss_list['cls'].append(cls_loss.item())\n",
    "    loss_list['lip'].append(lip_loss.item())\n",
    "    model.eval()\n",
    "    output = model(G, features)\n",
    "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "    roc_val = roc_auc_score(labels[idx_val].cpu().numpy(),output[idx_val].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    parity_val, equality_val = fair_metric(output,idx_val)\n",
    "\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    roc_test = roc_auc_score(labels[idx_test].cpu().numpy(),output[idx_test].detach().cpu().numpy())\n",
    "    parity,equality = fair_metric(output,idx_test)\n",
    "    if acc_val > args.acc and roc_val > args.roc:\n",
    "        acc_test_list.append(acc_test.item())\n",
    "        roc_test_list.append(roc_test)\n",
    "        parity_list.append(parity)\n",
    "        equality_list.append(equality)\n",
    "        if best_fair > parity_val + equality_val :\n",
    "            best_fair = parity_val + equality_val\n",
    "\n",
    "            best_result['acc'] = acc_test.item()\n",
    "            best_result['roc'] = roc_test\n",
    "            best_result['parity'] = parity\n",
    "            best_result['equality'] = equality\n",
    "\n",
    "        print(\"=================================\")\n",
    "\n",
    "        print('Epoch: {:04d}'.format(epoch+1),\n",
    "            'cls: {:.4f}'.format(cls_loss.item()),\n",
    "            'lip: {:.4f}'.format(lip_loss.item()),\n",
    "            'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "            \"roc_val: {:.4f}\".format(roc_val),\n",
    "            \"parity_val: {:.4f}\".format(parity_val),\n",
    "            \"equality: {:.4f}\".format(equality_val))\n",
    "        print(\"Test:\",\n",
    "                \"accuracy: {:.4f}\".format(acc_test.item()),\n",
    "                \"roc: {:.4f}\".format(roc_test),\n",
    "                \"parity: {:.4f}\".format(parity),\n",
    "                \"equality: {:.4f}\".format(equality))\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "print('============performace on test set=============')\n",
    "if len(best_result) > 0:\n",
    "    print(\"Test:\",\n",
    "            \"accuracy: {:.4f}\".format(best_result['acc']),\n",
    "            \"roc: {:.4f}\".format(best_result['roc']),\n",
    "            \"parity: {:.4f}\".format(best_result['parity']),\n",
    "            \"equality: {:.4f}\".format(best_result['equality']))\n",
    "    print(\"Test:\",\n",
    "            \"accuracy: {:.4f}\".format(np.mean(acc_test_list)),\n",
    "            \"roc: {:.4f}\".format(np.mean(roc_test_list)),             \n",
    "            \"parity: {:.4f}\".format(np.mean(parity_list)),\n",
    "            \"equality: {:.4f}\".format(np.mean(equality_list)))\n",
    "else:\n",
    "    print(\"Please set smaller acc/roc thresholds\")\n",
    "\n",
    "with open('loss.pk', 'wb') as handle:\n",
    "    pk.dump(loss_list, handle, protocol=pk.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c4c1446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_graph=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "709a5b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Epoch: 0534 cls: 0.6699 lip: 106.5875 acc_val: 0.7136 roc_val: 0.7639 parity_val: 0.0088 equality: 0.0671\n",
      "Test: accuracy: 0.7136 roc: 0.7639 parity: 0.0088 equality: 0.0671\n",
      "=================================\n",
      "Epoch: 0551 cls: 0.6682 lip: 107.8012 acc_val: 0.6948 roc_val: 0.7676 parity_val: 0.0168 equality: 0.0417\n",
      "Test: accuracy: 0.6948 roc: 0.7676 parity: 0.0168 equality: 0.0417\n",
      "=================================\n",
      "Epoch: 0677 cls: 0.6680 lip: 114.9420 acc_val: 0.7089 roc_val: 0.7673 parity_val: 0.0052 equality: 0.0293\n",
      "Test: accuracy: 0.7089 roc: 0.7673 parity: 0.0052 equality: 0.0293\n",
      "=================================\n",
      "Epoch: 0747 cls: 0.6666 lip: 116.7011 acc_val: 0.7230 roc_val: 0.7662 parity_val: 0.0690 equality: 0.0783\n",
      "Test: accuracy: 0.7230 roc: 0.7662 parity: 0.0690 equality: 0.0783\n",
      "=================================\n",
      "Epoch: 0781 cls: 0.6697 lip: 94.8912 acc_val: 0.6948 roc_val: 0.7641 parity_val: 0.0326 equality: 0.0301\n",
      "Test: accuracy: 0.6948 roc: 0.7641 parity: 0.0326 equality: 0.0301\n",
      "=================================\n",
      "Epoch: 0815 cls: 0.6638 lip: 129.2169 acc_val: 0.6901 roc_val: 0.7647 parity_val: 0.0261 equality: 0.0181\n",
      "Test: accuracy: 0.6901 roc: 0.7647 parity: 0.0261 equality: 0.0181\n",
      "=================================\n",
      "Epoch: 0819 cls: 0.6692 lip: 90.5558 acc_val: 0.7136 roc_val: 0.7670 parity_val: 0.0506 equality: 0.0189\n",
      "Test: accuracy: 0.7136 roc: 0.7670 parity: 0.0506 equality: 0.0189\n",
      "=================================\n",
      "Epoch: 0823 cls: 0.6715 lip: 76.0103 acc_val: 0.7136 roc_val: 0.7704 parity_val: 0.0193 equality: 0.0551\n",
      "Test: accuracy: 0.7136 roc: 0.7704 parity: 0.0193 equality: 0.0551\n",
      "=================================\n",
      "Epoch: 0828 cls: 0.6674 lip: 105.7487 acc_val: 0.7042 roc_val: 0.7638 parity_val: 0.0661 equality: 0.0430\n",
      "Test: accuracy: 0.7042 roc: 0.7638 parity: 0.0661 equality: 0.0430\n",
      "=================================\n",
      "Epoch: 0833 cls: 0.6621 lip: 158.3605 acc_val: 0.6901 roc_val: 0.7680 parity_val: 0.0183 equality: 0.0534\n",
      "Test: accuracy: 0.6901 roc: 0.7680 parity: 0.0183 equality: 0.0534\n",
      "=================================\n",
      "Epoch: 0855 cls: 0.6677 lip: 102.9873 acc_val: 0.7324 roc_val: 0.7653 parity_val: 0.0506 equality: 0.0430\n",
      "Test: accuracy: 0.7324 roc: 0.7653 parity: 0.0506 equality: 0.0430\n",
      "=================================\n",
      "Epoch: 0888 cls: 0.6669 lip: 103.5061 acc_val: 0.7230 roc_val: 0.7702 parity_val: 0.0611 equality: 0.0667\n",
      "Test: accuracy: 0.7230 roc: 0.7702 parity: 0.0611 equality: 0.0667\n",
      "=================================\n",
      "Epoch: 0905 cls: 0.6660 lip: 110.9096 acc_val: 0.7089 roc_val: 0.7654 parity_val: 0.0625 equality: 0.0542\n",
      "Test: accuracy: 0.7089 roc: 0.7654 parity: 0.0625 equality: 0.0542\n",
      "=================================\n",
      "Epoch: 0914 cls: 0.6671 lip: 103.0333 acc_val: 0.7136 roc_val: 0.7653 parity_val: 0.0690 equality: 0.0663\n",
      "Test: accuracy: 0.7136 roc: 0.7653 parity: 0.0690 equality: 0.0663\n",
      "=================================\n",
      "Epoch: 0982 cls: 0.6676 lip: 100.7800 acc_val: 0.7230 roc_val: 0.7732 parity_val: 0.0272 equality: 0.0168\n",
      "Test: accuracy: 0.7230 roc: 0.7732 parity: 0.0272 equality: 0.0168\n",
      "=================================\n",
      "Epoch: 1010 cls: 0.6634 lip: 142.3608 acc_val: 0.7089 roc_val: 0.7614 parity_val: 0.0495 equality: 0.0422\n",
      "Test: accuracy: 0.7089 roc: 0.7614 parity: 0.0495 equality: 0.0422\n",
      "=================================\n",
      "Epoch: 1014 cls: 0.6645 lip: 123.6355 acc_val: 0.7230 roc_val: 0.7749 parity_val: 0.0017 equality: 0.0435\n",
      "Test: accuracy: 0.7230 roc: 0.7749 parity: 0.0017 equality: 0.0435\n",
      "=================================\n",
      "Epoch: 1080 cls: 0.6641 lip: 129.0411 acc_val: 0.7183 roc_val: 0.7649 parity_val: 0.0885 equality: 0.0904\n",
      "Test: accuracy: 0.7183 roc: 0.7649 parity: 0.0885 equality: 0.0904\n",
      "=================================\n",
      "Epoch: 1132 cls: 0.6638 lip: 127.3456 acc_val: 0.7042 roc_val: 0.7693 parity_val: 0.0560 equality: 0.0422\n",
      "Test: accuracy: 0.7042 roc: 0.7693 parity: 0.0560 equality: 0.0422\n",
      "=================================\n",
      "Epoch: 1144 cls: 0.6675 lip: 106.6300 acc_val: 0.7042 roc_val: 0.7679 parity_val: 0.0560 equality: 0.0422\n",
      "Test: accuracy: 0.7042 roc: 0.7679 parity: 0.0560 equality: 0.0422\n",
      "=================================\n",
      "Epoch: 1190 cls: 0.6674 lip: 92.6632 acc_val: 0.7089 roc_val: 0.7654 parity_val: 0.0625 equality: 0.0542\n",
      "Test: accuracy: 0.7089 roc: 0.7654 parity: 0.0625 equality: 0.0542\n",
      "=================================\n",
      "Epoch: 1219 cls: 0.6602 lip: 166.5695 acc_val: 0.6901 roc_val: 0.7637 parity_val: 0.0600 equality: 0.0538\n",
      "Test: accuracy: 0.6901 roc: 0.7637 parity: 0.0600 equality: 0.0538\n",
      "=================================\n",
      "Epoch: 1223 cls: 0.6624 lip: 144.7584 acc_val: 0.7042 roc_val: 0.7614 parity_val: 0.1080 equality: 0.0904\n",
      "Test: accuracy: 0.7042 roc: 0.7614 parity: 0.1080 equality: 0.0904\n",
      "=================================\n",
      "Epoch: 1227 cls: 0.6627 lip: 129.7629 acc_val: 0.7136 roc_val: 0.7784 parity_val: 0.0142 equality: 0.0409\n",
      "Test: accuracy: 0.7136 roc: 0.7784 parity: 0.0142 equality: 0.0409\n",
      "=================================\n",
      "Epoch: 1288 cls: 0.6631 lip: 143.5471 acc_val: 0.7136 roc_val: 0.7736 parity_val: 0.0142 equality: 0.0069\n",
      "Test: accuracy: 0.7136 roc: 0.7736 parity: 0.0142 equality: 0.0069\n",
      "=================================\n",
      "Epoch: 1292 cls: 0.6651 lip: 111.1399 acc_val: 0.6995 roc_val: 0.7698 parity_val: 0.0182 equality: 0.0185\n",
      "Test: accuracy: 0.6995 roc: 0.7698 parity: 0.0182 equality: 0.0185\n",
      "=================================\n",
      "Epoch: 1318 cls: 0.6641 lip: 121.7670 acc_val: 0.6995 roc_val: 0.7705 parity_val: 0.0052 equality: 0.0413\n",
      "Test: accuracy: 0.6995 roc: 0.7705 parity: 0.0052 equality: 0.0413\n",
      "=================================\n",
      "Epoch: 1343 cls: 0.6607 lip: 149.9557 acc_val: 0.6948 roc_val: 0.7651 parity_val: 0.0430 equality: 0.0181\n",
      "Test: accuracy: 0.6948 roc: 0.7651 parity: 0.0430 equality: 0.0181\n",
      "=================================\n",
      "Epoch: 1347 cls: 0.6600 lip: 162.3930 acc_val: 0.7183 roc_val: 0.7649 parity_val: 0.0885 equality: 0.0904\n",
      "Test: accuracy: 0.7183 roc: 0.7649 parity: 0.0885 equality: 0.0904\n",
      "=================================\n",
      "Epoch: 1356 cls: 0.6609 lip: 150.1597 acc_val: 0.6995 roc_val: 0.7613 parity_val: 0.0391 equality: 0.0422\n",
      "Test: accuracy: 0.6995 roc: 0.7613 parity: 0.0391 equality: 0.0422\n",
      "=================================\n",
      "Epoch: 1365 cls: 0.6625 lip: 134.7685 acc_val: 0.7042 roc_val: 0.7621 parity_val: 0.0481 equality: 0.0306\n",
      "Test: accuracy: 0.7042 roc: 0.7621 parity: 0.0481 equality: 0.0306\n",
      "=================================\n",
      "Epoch: 1480 cls: 0.6597 lip: 153.8379 acc_val: 0.7042 roc_val: 0.7650 parity_val: 0.0586 equality: 0.0663\n",
      "Test: accuracy: 0.7042 roc: 0.7650 parity: 0.0586 equality: 0.0663\n",
      "=================================\n",
      "Epoch: 1503 cls: 0.6597 lip: 154.0851 acc_val: 0.7089 roc_val: 0.7723 parity_val: 0.0286 equality: 0.0185\n",
      "Test: accuracy: 0.7089 roc: 0.7723 parity: 0.0286 equality: 0.0185\n",
      "=================================\n",
      "Epoch: 1538 cls: 0.6642 lip: 114.8922 acc_val: 0.7183 roc_val: 0.7706 parity_val: 0.0337 equality: 0.0310\n",
      "Test: accuracy: 0.7183 roc: 0.7706 parity: 0.0337 equality: 0.0310\n",
      "=================================\n",
      "Epoch: 1548 cls: 0.6600 lip: 162.8510 acc_val: 0.6948 roc_val: 0.7669 parity_val: 0.0355 equality: 0.0194\n",
      "Test: accuracy: 0.6948 roc: 0.7669 parity: 0.0355 equality: 0.0194\n",
      "=================================\n",
      "Epoch: 1721 cls: 0.6639 lip: 111.6956 acc_val: 0.7042 roc_val: 0.7678 parity_val: 0.0092 equality: 0.0052\n",
      "Test: accuracy: 0.7042 roc: 0.7678 parity: 0.0092 equality: 0.0052\n",
      "=================================\n",
      "Epoch: 1726 cls: 0.6559 lip: 197.7398 acc_val: 0.6901 roc_val: 0.7694 parity_val: 0.0183 equality: 0.0056\n",
      "Test: accuracy: 0.6901 roc: 0.7694 parity: 0.0183 equality: 0.0056\n",
      "=================================\n",
      "Epoch: 1730 cls: 0.6645 lip: 114.6124 acc_val: 0.7042 roc_val: 0.7813 parity_val: 0.0352 equality: 0.0770\n",
      "Test: accuracy: 0.7042 roc: 0.7813 parity: 0.0352 equality: 0.0770\n",
      "=================================\n",
      "Epoch: 1735 cls: 0.6596 lip: 160.3943 acc_val: 0.7089 roc_val: 0.7628 parity_val: 0.0806 equality: 0.1145\n",
      "Test: accuracy: 0.7089 roc: 0.7628 parity: 0.0806 equality: 0.1145\n",
      "=================================\n",
      "Epoch: 1772 cls: 0.6631 lip: 124.0265 acc_val: 0.7089 roc_val: 0.7663 parity_val: 0.0500 equality: 0.0280\n",
      "Test: accuracy: 0.7089 roc: 0.7663 parity: 0.0500 equality: 0.0280\n",
      "=================================\n",
      "Epoch: 1776 cls: 0.6647 lip: 109.8338 acc_val: 0.7277 roc_val: 0.7725 parity_val: 0.0500 equality: 0.0039\n",
      "Test: accuracy: 0.7277 roc: 0.7725 parity: 0.0500 equality: 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "Epoch: 1812 cls: 0.6632 lip: 124.6200 acc_val: 0.6995 roc_val: 0.7604 parity_val: 0.0806 equality: 0.1024\n",
      "Test: accuracy: 0.6995 roc: 0.7604 parity: 0.0806 equality: 0.1024\n",
      "=================================\n",
      "Epoch: 1904 cls: 0.6608 lip: 146.0544 acc_val: 0.7183 roc_val: 0.7681 parity_val: 0.0258 equality: 0.0671\n",
      "Test: accuracy: 0.7183 roc: 0.7681 parity: 0.0258 equality: 0.0671\n",
      "=================================\n",
      "Epoch: 1908 cls: 0.6631 lip: 128.1092 acc_val: 0.7230 roc_val: 0.7734 parity_val: 0.0193 equality: 0.0194\n",
      "Test: accuracy: 0.7230 roc: 0.7734 parity: 0.0193 equality: 0.0194\n",
      "=================================\n",
      "Epoch: 1975 cls: 0.6607 lip: 133.2095 acc_val: 0.7089 roc_val: 0.7635 parity_val: 0.0023 equality: 0.0551\n",
      "Test: accuracy: 0.7089 roc: 0.7635 parity: 0.0023 equality: 0.0551\n",
      "=================================\n",
      "Epoch: 1983 cls: 0.6582 lip: 162.2287 acc_val: 0.7089 roc_val: 0.7688 parity_val: 0.0128 equality: 0.0430\n",
      "Test: accuracy: 0.7089 roc: 0.7688 parity: 0.0128 equality: 0.0430\n",
      "Optimization Finished!\n",
      "Total time elapsed: 38.3942s\n",
      "============performace on test set=============\n",
      "Test: accuracy: 0.7042 roc: 0.7678 parity: 0.0092 equality: 0.0052\n",
      "Test: accuracy: 0.7083 roc: 0.7675 parity: 0.0408 equality: 0.0453\n"
     ]
    }
   ],
   "source": [
    "# model = FairGNN(nfeat = features.shape[1], args = args)\n",
    "model = VarFairGNN(nfeat = features.shape[1], args = args,aux_graph=sim_graph)\n",
    "# model.estimator.load_state_dict(torch.load(\"./checkpoint/GCN_sens_{}_ns_{}\".format(dataset,sens_number)))\n",
    "if args.cuda:\n",
    "    G = G.to(torch.device('cuda:0'))\n",
    "    model.cuda()\n",
    "    features = features.cuda()\n",
    "    labels = labels.cuda()\n",
    "    idx_train = idx_train.cuda()\n",
    "    idx_val = idx_val.cuda()\n",
    "    idx_test = idx_test.cuda()\n",
    "    sens = sens.cuda()\n",
    "    idx_sens_train = idx_sens_train.cuda()\n",
    "\n",
    "\n",
    "# Train model\n",
    "t_total = time.time()\n",
    "best_result = {}\n",
    "best_fair = 100\n",
    "\n",
    "acc_test_list = []\n",
    "roc_test_list = []\n",
    "parity_list = []\n",
    "equality_list = []\n",
    "loss_list = {'cls': [], 'lip':[]}\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    t = time.time()\n",
    "    model.train()\n",
    "    model.optimize(G,features,labels,idx_train,sens,idx_sens_train)\n",
    "    cls_loss = model.cls_loss\n",
    "    lip_loss = model.lip_loss\n",
    "    loss_list['cls'].append(cls_loss.item())\n",
    "    loss_list['lip'].append(lip_loss.item())\n",
    "    model.eval()\n",
    "    output = model(G, features)\n",
    "    acc_val = accuracy(output[idx_val], labels[idx_val])\n",
    "    roc_val = roc_auc_score(labels[idx_val].cpu().numpy(),output[idx_val].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    parity_val, equality_val = fair_metric(output,idx_val)\n",
    "\n",
    "    acc_test = accuracy(output[idx_test], labels[idx_test])\n",
    "    roc_test = roc_auc_score(labels[idx_test].cpu().numpy(),output[idx_test].detach().cpu().numpy())\n",
    "    parity,equality = fair_metric(output,idx_test)\n",
    "    if acc_val > args.acc and roc_val > args.roc:\n",
    "        acc_test_list.append(acc_test.item())\n",
    "        roc_test_list.append(roc_test)\n",
    "        parity_list.append(parity)\n",
    "        equality_list.append(equality)\n",
    "        if best_fair > parity_val + equality_val :\n",
    "            best_fair = parity_val + equality_val\n",
    "\n",
    "            best_result['acc'] = acc_test.item()\n",
    "            best_result['roc'] = roc_test\n",
    "            best_result['parity'] = parity\n",
    "            best_result['equality'] = equality\n",
    "\n",
    "        print(\"=================================\")\n",
    "\n",
    "        print('Epoch: {:04d}'.format(epoch+1),\n",
    "            'cls: {:.4f}'.format(cls_loss.item()),\n",
    "            'lip: {:.4f}'.format(lip_loss.item()),\n",
    "            'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "            \"roc_val: {:.4f}\".format(roc_val),\n",
    "            \"parity_val: {:.4f}\".format(parity_val),\n",
    "            \"equality: {:.4f}\".format(equality_val))\n",
    "        print(\"Test:\",\n",
    "                \"accuracy: {:.4f}\".format(acc_test.item()),\n",
    "                \"roc: {:.4f}\".format(roc_test),\n",
    "                \"parity: {:.4f}\".format(parity),\n",
    "                \"equality: {:.4f}\".format(equality))\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "print('============performace on test set=============')\n",
    "if len(best_result) > 0:\n",
    "    print(\"Test:\",\n",
    "            \"accuracy: {:.4f}\".format(best_result['acc']),\n",
    "            \"roc: {:.4f}\".format(best_result['roc']),\n",
    "            \"parity: {:.4f}\".format(best_result['parity']),\n",
    "            \"equality: {:.4f}\".format(best_result['equality']))\n",
    "    print(\"Test:\",\n",
    "            \"accuracy: {:.4f}\".format(np.mean(acc_test_list)),\n",
    "            \"roc: {:.4f}\".format(np.mean(roc_test_list)),             \n",
    "            \"parity: {:.4f}\".format(np.mean(parity_list)),\n",
    "            \"equality: {:.4f}\".format(np.mean(equality_list)))\n",
    "else:\n",
    "    print(\"Please set smaller acc/roc thresholds\")\n",
    "\n",
    "with open('loss.pk', 'wb') as handle:\n",
    "    pk.dump(loss_list, handle, protocol=pk.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd4bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37] *",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
